\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}          
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{csquotes}
\usepackage{setspace}\onehalfspacing
\usepackage[loose,nice]{units} %replace "nice" by "ugly" for units in upright fractions
\usepackage{graphicx}
\graphicspath{ {/Users/eghuang/math104/images/} }
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{
  Notes on Inference Devices \\
  \large Santa Fe Institute}
\author{Edward G. Huang}
\date{Summer 2018} 
 
 \newcommand{\R}{\mathbb{R}}
 \newcommand{\Q}{\mathbb{Q}}
 \newcommand{\Z}{\mathbb{Z}}
 \newcommand{\N}{\mathbb{N}}
 \newcommand{\B}{\mathbb{B}}
 \newcommand{\Prob}{\mathbb{P}}
 \newcommand{\E}{\mathbb{E}}
 \newcommand{\code}[1]{\texttt{#1}}
 \let\oldemptyset\emptyset
 \let\emptyset\varnothing
 
 \setlength{\parindent}{0pt} % no indent
 
\begin{document}
\maketitle 

% SECTION 1: NOTATION
\section{Notation and Definitions} 

Standard notation is taken from set theory and vector algebra. We clarify some notation specific to computation and inference devices. \\


\subsection{Turing Machines} 

$ \B^{*} \quad $ The space of all finite bit strings. \\
$ \Lambda \quad $ Symbol alphabet of a Turing Machine. \\
$ \sigma \quad $ A symbol on a Turing Machine tape. \\
$ Q \quad $ Set of finite states of a Turing Machine. \\
$ \Delta \quad $ Transition function of a Turing Machine. \\
$ k \quad $ Number of tapes of a Turing Machine. The first tape is assumed to be read-only. \\
$ \eta \quad $ Non-halting state of a Turing Machine. \\


\subsection{Inference Devices} 
$ U \quad $ Set of possible histories of the universe. \\
$ u \quad $ A history of the universe in $ U $. \\ 
$ X \quad $ Setup function of an ID that maps $ U \rightarrow X(U) $. A binary question concerning $ \Gamma(u) $. \\
$ x \quad $ A binary question and a member of image $ X(U) $. \\ 
$ Y \quad $ Single-valued conclusion function of an ID that maps $ U \rightarrow \{-1, 1\} $. A binary answer of an ID for  $ X(u) = x $. \\ 
$ y \quad $ A single-valued answer, and member of image $ Y(U)  = \{0, 1\} $. \\ 
$ \Gamma \quad $ A function of the actual values of a physical variable over $U$, equivalent to $\Gamma(u) = S(t_i)(u)$.  \\
$ \gamma \quad $ Possible value of a physical variable, a member of the image $\Gamma(U)$. \\
$ \delta \quad $ Probe of any variable $V$ parameterized by $v \in V$ such that : 
	  \[ \delta_v (v') =
	  \begin{cases} 
       1 & \text{ if } v = v' \\
       -1 & \text{ otherwise } \\
      \end{cases}\] \\
$ \wp \quad $ Set of probes over $\Gamma(U)$. \\
$ \mathcal{D} = (X, Y) \quad $ An inference device, consisting of functions $ X $ and $ Y $. \\
$ \quad \bar{F} \quad $ Inverse. Given a function $ F $ over $ U $, $F ^ {-1} = \bar{F} \equiv \{\{u : F(u) = f \} : f \in F(U) \} $. \\
$ > \quad $ Weak inference: a device $\mathcal{D}$ weakly infers $\Gamma$ \textit{iff} $ \forall \gamma \in \Gamma(U), \exists x \in X(U) $ s.t. $ \forall u \in U $, 

$ \quad \quad X(u) = x \implies Y(u) = \delta_{\gamma}(\Gamma(u)) $.  \\
$ \gg \quad $ Strong inference: a device $ (X, Y) $ strongly infers a functions $ (S, T) $ over $ U $ \textit{ iff } $\forall \delta \in \wp(T) $ 

\quad \quad and all $ s \in S(U) $, $ \exists x $ \textit{ such that } $ X(u) = x \implies S(u) = s, Y(u) = \delta(T(u)) $. \\

% SECTION 2: TURING MACHINES
\section{Turing Machines} 

\subsection{Deterministic Turing Machines} 

 Arora and Barak denote a Turing Machine (TM) as $ T = (\Lambda, Q, \Delta) $ containing:
\begin{enumerate}
\item An \textit{alphabet} $ \Lambda $ of a finite set of symbols that $ T $'s tapes can contain. We assume that $ \Lambda $ contains a special blank symbol $ B $, start symbol $ S $, and the symbols 0 and 1. 
\item A finite set $ Q $ of possible states that $ T $'s register can be in. We assume that $ Q $ contains a special start state $ q_{s} $ and a special halt state $ q_{h} $. 
\item A transition function function $ \Delta : Q \times \Lambda^{k} \rightarrow Q \times \Lambda^{k - 1} \times \{L, S, R\}^{k} $, where $ k \geq 2$, describing the rules $ T $ use in performing each step. The set $\{L ,S, R\}$ denote the actions \textit{Left, Stay,} and \textit{Right}, respectively. 
\end{enumerate}

Suppose $ T $ is in state $ q \in Q $ and $ (\sigma_1, \sigma_2, \dots, \sigma_k) $ are the symbols on the $ k $ tapes. Then $ \Delta(q, (\sigma_1, \dots, \sigma_k)) = (q', (\sigma_{2}^{'}, \dots, \sigma_{k}^{'}), z) $ where $ z \in \{L, S, R\}^k $ and at the next step the $ \sigma $ symbols in the last $ k - 1 $ tapes will be replaced by the $ \sigma' $ symbols, the machine will be in state $ q $, and the $ k $ heads will move \textit{Left, Right} or \textit{Stay}. This is illustrated in Figure 1. \\

\textbf{Figure 2.1. The transition function $ \Delta $ for a $ k $-tape Turing Machine}

 \begin{center}
 \begin{tabular}{ c|c|c|c||c|c|c|c|c} 
 \multicolumn{4}{c||}{ $ (q, (\sigma_1, \dots, \sigma_k)) $ } & 
      \multicolumn{5}{c}{ $ (q', (\sigma_{2}^{'}, \dots, \sigma_{k}^{'}), z) $ } \\
 
 \hline
 \begin{tabular}[c]{@{}c@{}} Input \\ symbol \end{tabular} & 
 \begin{tabular}[c]{@{}c@{}} Work/output \\ symbol \\ read \end{tabular} & 
 $\dots $ &
 \begin{tabular}[c]{@{}c@{}} Current \\ state \end{tabular} &
 \begin{tabular}[c]{@{}c@{}} New \\ work/output \\ tape symbol \end{tabular} & 
 $ \dots $ &
 \begin{tabular}[c]{@{}c@{}} Move \\ work/output \\ tape \end{tabular} &
 $ \dots $ &
 \begin{tabular}[c]{@{}c@{}} New \\ state \end{tabular} \\ 
 
 \hline
 \hline
 $ \vdots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ \\ 
 \hline
 $  \sigma_1 $ & $ \sigma_i $ & $ \ddots $ & $ q $ & $ \sigma_i^{'} $ & $ \ddots $ & $ z_i $ & $ \ddots $ & $ q^{'} $ \\ 
 \hline
 $ \vdots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ & $ \ddots $ & $ \vdots $ \\ 
 \end{tabular}
 \end{center} 

\bigbreak

\textit{Remark}: $\Lambda$ can be reduced to $ \B = \{0, 1\} $ and $ k $ can be reduced to $ 1 $ without loss of computational power. Then, any Turing Machine can be expressed as a partial recursive function mapping $ \B^{*} \rightarrow \B^{*} \cup \eta $, where $ \eta $ is the undefined non-halting output. Since $ |\B^{*} \times \B^{*} \cup \eta | = | \N \times \N | = | \N | $, the set of all Turing Machines is countably infinite. 

\subsection{Non-deterministic Turing Machines} 

Non-deterministic Turing Machines (NDTM) differ from deterministic Turing Machines by having two transition functions $ \Delta_0, \Delta_1 $ and a special state $ q_{accept} $. From Arora and Barak:

\begin{displayquote}
When a NDTM $M$ computes a function, we envision that at each computational step $ M $ makes an arbitrary choice as to which of its two transition functions to apply. For every input $ x $, we say that $ M(x) = 1 $ if there exists some sequence of these choices (which we call nondeterministic choices of $ M $) that would make $ M $ reach $ q_{accept} $ on input $ x $. Otherwise - if every sequence of choices makes $ M $ halt without reaching $ q_{accept} $ - then we say that $ M(x) = 0 $.
\end{displayquote}


% SECTION 3: INFERENCE OF TURING MACHINES
\section{Inference of Turing Machines} 
 
 In the next two examples we examine strong inference of simple single-valued functions. \\
 
 
 \textbf{Example 3.1} \quad Let $ T(U) = \{0 , 1\} $ and $ S(U) = \{0, 1, 2\} $. We construct $ (X, Y) $ in the table at the left such that it strongly infers $ (S, T) $. The right table indicates $ x $ for each $ s $, $ \delta $ such that the definition of strong inference is satisfied: \\ 
 \begin {center}
 \begin{tabular}{ c||c|c|c|c } 

 $ u $ & $ X(u) $ & $ Y(u) $ & $ S(u) $ & $ T(u) $ \\ 
 \hline
 \hline
 $ 1 $ & $ 1 $ & $ 1 $ & $ 0 $ & $ 0 $ \\
 \hline
 $ 2 $ & $ 2 $ & $ -1 $ & $ 0 $ & $ 0 $ \\
 \hline
 $ 3 $ & $ 3 $ & $ 1 $ & $ 1 $ & $ 0 $ \\
 \hline
 $ 4 $ & $ 4 $ & $ -1 $ & $ 1 $ & $ 0 $ \\
 \hline 
 $ 5 $ & $ 5 $ & $ 1 $ & $ 2 $ & $ 1 $ \\
 \hline 
 $ 6 $ & $ 6 $ & $ -1 $ & $ 2 $ & $ 1 $ \\
 \end{tabular} 
 \quad 
 \begin{tabular}{ c||c|c } 

 $ (s, \delta) $ & $ \delta_0 $ & $ \delta_1 $ \\ 
 \hline
 \hline
 $ 0 $ & $ 1 $ & $ 2 $  \\
 \hline
 $ 1 $ & $ 3 $ & $ 4 $ \\
 \hline
 $ 2 $ & $ 6 $ & $ 5 $ \\
 
 \end{tabular}
 \end{center}
 
  
 \bigbreak
 \bigbreak 
 \textbf{Example 3.2} \quad Let $ T(U) = \{1, 2, 3\} $ and $ S(U) = \{1, 2, 3, 4, 5\} $. Again, we construct $ (X, Y) $ in the table at the left such that it strongly infers $ (S, T) $. The right table indicates $ x $ for each $ s $, $ \delta $ such that the definition of strong inference is satisfied: \\ 

 \begin{center}
 \begin{tabular}{ c||c|c|c|c } 

 $ u $ & $ X(u) $ & $ Y(u) $ & $ S(u) $ & $ T(u) $ \\ 
 \hline
 \hline
 $ 1 $ & $ 1 $ & $ 1 $ & $ 1 $ & $ 1 $ \\
 \hline
 $ 2 $ & $ 2 $ & $ -1 $ & $ 2 $ & $ 1 $ \\
 \hline
 $ 3 $ & $ 3 $ & $ -1 $ & $ 3 $ & $ 2 $ \\
 \hline
 $ 4 $ & $ 4 $ & $ -1 $ & $ 4 $ & $ 2 $ \\
 \hline
 $ 5 $ & $ 5 $ & $ -1 $ & $ 5 $ & $ 3 $ \\
 \hline
 $ 6 $ & $ 6 $ & $ 1 $ & $ 2 $ & $ 1 $ \\
 \hline
 $ 7 $ & $ 7 $ & $ -1 $ & $ 1 $ & $ 1 $ \\
 \hline
 $ 8 $ & $ 8 $ & $ 1 $ & $ 3 $ & $ 2 $ \\
 \hline
 $ 9 $ & $ 9 $ & $ 1 $ & $ 4 $ & $ 2 $ \\
 \hline
 $ 10 $ & $ 10 $ & $ 1 $ & $ 5 $ & $ 3 $ \\ 
 \end{tabular} 
 \quad
 \begin{tabular}{ c||c|c|c|c|c } 

 $ (s, \delta) $ & $ \delta_1 $ & $ \delta_1 $ & $ \delta_1 $ & $ \delta_1 $ & $ \delta_1 $ \\ 
 \hline
 \hline
 $ 1 $ & $ 1 $ & $ 7 $ & $ 7 $ & $ 7 $ & $ 7 $ \\
 \hline
 $ 2 $ & $ 6 $ & $ 2 $ & $ 2 $ & $ 2 $ & $ 2 $ \\
 \hline
 $ 3 $ & $ 3 $ & $ 8 $ & $ 3 $ & $ 3 $ & $ 3 $ \\
 \hline
 $ 4 $ & $ 4 $ & $ 9 $ & $ 4 $ & $ 4 $ & $ 4 $ \\
 \hline 
 $ 5 $ & $ 5 $ & $ 5 $ & $ 10 $ & $ 5 $ & $ 5 $ \\
 
 \end{tabular}
 \end{center} 

\bigskip 
\bigskip
\textbf{Theorem} \quad \textit{A deterministic Turing Machine can be strongly inferred by a device if} 
$$\forall s \in S(U),\; |S^{-1}(s)| \geq 2. $$ \textit{The condition holds for both the partial recursive function description and the instantaneous description of Turing machines.} \\

\textbf{Proof} \quad We first examine the partial function case. Let $ f $ be the partial recursive function that describes a Turing Machine. Let $ U := \N $. Define $ S: U \rightarrow \B^{*} $ as the single-valued function mapping $ U $ to the space of binary string inputs and define $ T: U \rightarrow \B^{*} \cup \eta$ given by $T(u) = f(S(u)) $ as the single-valued function mapping $ U $ to the halting and non-halting outputs of $ f $. Then $ f $ can be written as the single-valued mapping $ S \rightarrow T $ given by $ f(s) = T(S^{-1}(s)) $ \\

% delta and f must be in definitions of s and t.

Let $ V = \{u : S^{-1}(s) = u \} $ for a value of $ s \in S(U) $. Enumerate the elements of $V$ as $v_1, v_2, \dots , v_n$. Then define $ X $ and $ Y $ as follows:

\begin{equation*}
Y(v) = \begin{cases}
       1 & \text{ if } v = v_1 \\
       -1 & \text{ otherwise } \\
       \end{cases} \quad \quad
X(v_i) = i, i \in \N
\end{equation*}

\bigskip
Then for each pair $ (s, \delta_{t \in T(U)} ) $ choose $ x_1 $ if $ t = T(v_1) $ or otherwise choose $ x_2 $ to force $ S(u) = s $ and $ Y(u) = \delta_{t}(T(u)) $. Since the choice of $ s $ was arbitrary, this holds for all $ (s, \delta_t) $ pairs. \\


Now consider the instantaneous description of Turing Machines. The instantaneous description can be described by a function $ \Delta $ mapping $ Q \times \Lambda^{k} \rightarrow Q \times \Lambda^{k - 1} \times \{ L, S, R \} ^{k} $, $ k \geq 2 $. Consider the single-valued functions $ S: U \rightarrow Q \times \Lambda^{k} $ representing the possible inputs for a Turing Machine and $ T: U \rightarrow Q \times \Lambda^{k - 1} \times \{ L, S, R \}^ {k} $ given by $ T(u) = \Delta(S(u)) $. Then $ \Delta $ can be written as the single-valued function $ \Delta(s) = T(S^{-1}(s)) $ \\

We proceed similarly to the partial function portion of the proof. Define $ V $, $ X $, $ Y $ as described in the preceding sections. For each pair $ (s, \delta_{t \in T(U)} ) $ choose $ x_1 $ if $ t = T(v_1) $ or otherwise choose $ x_2 $ to force $ S(u) = s $ and $ Y(u) = \delta_{t}(T(u)) $. Since the choice of $ s $ was arbitrary, this holds for all $ (s, \delta_t) $ pairs. $ \hfill \qed $ \\

% NECESSARY <- PROOF, DOES NOT CONSIDER CASE WHERE TURING MACHINE NEVER HALTS
%Now for either case, suppose that $|V| < 2$ for some $ s $. If $ V = \emptyset $ then there exists no $ x $ that can force $ S = s $. If $ |V| = 1 $, then we can assign $ Y(v) = y \in \{-1, 1\} $. However, whatever value we assign, we cannot guarantee that $ \delta_{t}(T(v)) = Y(v) $ for all $ t $ since $ |T(U)| > 1 $. $ \hfill \qed $ \\



%\textbf {Theorem} \quad \textit{Any non-deterministic Turing Machine can be strongly inferred by a device iff} 
%$$\forall s \in S(U),\; |S^{-1}(s)| \geq 2. $$
%\textbf{Proof} \quad Let $ U := \N $. Define $ S: U \rightarrow \B^{*} $ to be a function that maps integers to binary bit strings and $ T: U \rightarrow \B^{*} \cup \eta$ as a function that maps $u$ to the space of bits strings union with the non-halting output $ \eta $. Define $ V = \{u : S^{-1}(s) \} $ for some value of $ s $. \\
% 
%Assume the function $ f: S \rightarrow T $ given by $ f(s) = T(S^{-1}(s)) $ may be multi-valued. Without loss of generality, fix $ s $. If $ T(S^{-1}(s) $ is \textit{single-valued,} choose $ x_1 $, $ x_2 $ as described in Proof 1. If $ T(S^{-1}(s) $ is \textit{multi-valued}, set $ Y(v_{1}) = -1 $ and $ Y(v_{2}) = -1 $. Then for each pair $ (s, \delta_{t \in T(U)} ) $ choose $ X(v_{1}) = x_1 $ if $ t \neq T(v_1) $ or otherwise choose $ X(v_2) = x_2 $. Since the choice of $ s $ was arbitrary, this holds for all $ (s, \delta_t) $ pairs. \\
%
%Now suppose that $|V| < 2$ for some $ s $. If $ V = \emptyset $ then there exists no $ x $ that can force $ S = s $. If $ |V| = 1 $, then we can assign $ Y(v) = y \in \{-1, 1\} $. However, whatever value we assign, we cannot guarantee that $ \delta_{t}(T(v)) = Y(v) $ for all $ t $ since $ |T(U)| \geq 1 $. $ \hfill \qed $ \\
%
%
%\textbf {Theorem} \quad \textit{Any update function of a deterministic Turing Machine can be strongly inferred by a device.} \\
%\textbf{Proof} \quad 
%
%\textbf {Theorem} \quad \textit{Any update function of a non-deterministic Turing Machine can be strongly inferred by a device.} \\
%\textbf{Proof} \quad 


% Hence:
%
%$$ \forall \delta \in \wp(T)\text{ and all } s \in S(U),  \exists x \textit{ such that } X(u) = x \implies \{S(u) = s, Y(u) = \delta(T(u))\} $$ 
%
%Since the choices of $S$ and $T$ were arbitrary, any Turing machine can be strongly inferred by an inference device. \\


%\textbf{Theorem} \quad \textit{Every Turing Machine can be weakly inferred by an inference device.}\\
%\textbf{Proof} \quad This follows from Proposition 4 and the preceding result.
%
%Let $ X : U \rightarrow \B^{*} $ be the lexicographic mapping of integers to binary bits strings such that 1 is alphabetically before 0. Then $ X(u) = x $ \textit{ iff } $S(u) = s $. Take $ Y : U \rightarrow \{0, 1\} $ to be the probe $ \delta_{T(u)}(T(u)) $. 


% choice of x influences choice of probe
% y is fixed
% probe is really just a mathematical relation that allows for us to ask yes/no question.

% Write theorem for any Turing Machine encode it as gamma such that there is an inference device that can weakly infer that function

% fix x and loop s, t

% Encode not the update rule but the entire map 

% Use countable spaces
% Gamma has to encode input string, output string or nonhalting 

% Does strong inference solve the Halting Problem? 

% Go through all the counting numbers, map from counting numbers to joint space (b, T_1(b))
% T(u) is a value in the space of strings union no halt such that T(u) is the associated output of S(u). 

% Use tuple to define Gamma, probe cares about second part 
% 

\section{Inference Complexity}

\textbf{Definition} \quad Let $ \mathcal{D} $ be an inference device and $ \Gamma $ be a function over $ U $ where $ X(U) $ and $ \Gamma(U) $ are countable and $ \mathcal{D} > \Gamma $. Let the \textbf{size} of $\gamma \in \Gamma(U) $ be written as $ \mathcal{M}_{\mu:\Gamma(\gamma)} = -\ln[\int_{\Gamma^{-1}(\gamma)} d\mu(u) 1] $. Then the \textbf{inference complexity} of $ \Gamma $ with respect to $ \mathcal{D} $ and measure $ \mu $ is defined as: 

$$ \mathcal{C}_{\mu}(\Gamma ; \mathcal{D}) \triangleq \sum_{\delta \in \wp(\Gamma)} min_{x : X = x \implies Y = \delta(\Gamma) } [\mathcal{M}_{\mu, X} (x)]	$$ 

\textit{Remark:} This is only a working definition and may be revised depending on its behavior.

% Make strong inference example for arxiv paper
% use a tuple for x <- (b, probe type)

\end{document}